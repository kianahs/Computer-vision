{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0baed7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "\n",
    "def generate_refrence_frame(all_frames, alpha):\n",
    "   \n",
    "    reference_frame = all_frames[0]\n",
    "    \n",
    "    for frame in all_frames:\n",
    "        \n",
    "        # Compute the weighted sum of the current frame and the reference frame\n",
    "        reference_frame = (alpha * frame + (1 - alpha) * reference_frame)\n",
    "        \n",
    "        frame_differences = np.abs(frame.astype(np.float32) - reference_frame.astype(np.float32)).astype(np.uint8)\n",
    "        \n",
    "    \n",
    "#     plt.imshow(reference_frame, cmap = 'gray')\n",
    "    \n",
    "    return reference_frame.astype(np.uint8)\n",
    "    \n",
    "def dfs(img, visited, x, y, label):\n",
    "    if x < 0 or x >= img.shape[0] or y < 0 or y >= img.shape[1] or visited[x, y] or img[x, y] == 0:\n",
    "        return\n",
    "\n",
    "    visited[x, y] = True\n",
    "    img[x, y] = label\n",
    "\n",
    "    # 8-connectivity neighbors\n",
    "    neighbors = [(-1, -1), (-1, 0), (-1, 1),\n",
    "                 (0, -1),           (0, 1),\n",
    "                 (1, -1), (1, 0), (1, 1)]\n",
    "\n",
    "    for dx, dy in neighbors:\n",
    "        dfs(img, visited, x + dx, y + dy, label)\n",
    "\n",
    "def find_contours(binary_image):\n",
    "    labeled_image = binary_image.copy()\n",
    "    visited = np.zeros_like(binary_image, dtype=bool)\n",
    "    label_count = 1\n",
    "\n",
    "    for x in range(binary_image.shape[0]):\n",
    "        for y in range(binary_image.shape[1]):\n",
    "            if not visited[x, y] and labeled_image[x, y] == 255:\n",
    "                dfs(labeled_image, visited, x, y, label_count)\n",
    "                label_count += 1\n",
    "\n",
    "    return labeled_image\n",
    "\n",
    "def count_objects(labeled_image):\n",
    "    unique_labels = np.unique(labeled_image)\n",
    "    object_count = len(unique_labels) - 1  # subtract background label\n",
    "    return object_count\n",
    "\n",
    "def count_moving_objects(video_path, reference_frame, threshold=30):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    object_counts = []\n",
    "\n",
    "    frame_count = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Calculate absolute difference between the current frame and the reference frame\n",
    "        frame_diff = cv2.absdiff(frame_gray, reference_frame)\n",
    "\n",
    "        # Apply threshold to classify pixels as moving or static\n",
    "        _, thresholded_frame = cv2.threshold(frame_diff, threshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Find contours manually without using findContours\n",
    "        labeled_frame = find_contours(thresholded_frame)\n",
    "\n",
    "        # Count the number of moving objects\n",
    "        object_count = count_objects(labeled_frame)\n",
    "        object_counts.append(object_count)\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    return object_counts\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0377044f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the video file\n",
    "video_capture = cv2.VideoCapture('Dataset//DatasetC.avi')  # Replace with your video file path\n",
    "\n",
    "# Check if the video file is opened successfully\n",
    "if not video_capture.isOpened():\n",
    "    print(\"Error: Could not open video file.\")\n",
    "    exit()\n",
    "\n",
    "# Loop through the frames and process each one\n",
    "\n",
    "frames = []\n",
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    if not ret:\n",
    "        break  # Break the loop if we've reached the end of the video\n",
    "\n",
    "    gray_image = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frames.append(gray_image)\n",
    "\n",
    "\n",
    "# # Release the video file and close the display window\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# c) Generate a reference frame using weighted temporal averaging\n",
    "reference_frame = generate_refrence_frame(frames, 0.027)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b94c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# d) Count the number of moving objects in each frame and plot the results\n",
    "object_counts = count_moving_objects('Dataset//DatasetC.avi', reference_frame, threshold=30)\n",
    "plot_object_counts(object_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd52438c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
